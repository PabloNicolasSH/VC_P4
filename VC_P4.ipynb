{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cargamos las librerías, los modelos con las clases que vamos a usar y definimos las variables globales que nos ayudarán con el conteo de las clases"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:15:04.140327Z",
     "start_time": "2024-11-08T16:15:02.198756Z"
    }
   },
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "yolo_classes = {\n",
    "    0: \"PERSONA\",\n",
    "    2: \"COCHE\",\n",
    "    3: \"MOTO\",\n",
    "    5: \"GUAGUA\"\n",
    "}\n",
    "model = YOLO('yolo11n.pt')\n",
    "model_plates = YOLO('best.pt')\n",
    "\n",
    "class_counts = {key: 0 for key in yolo_classes.values()}\n",
    "track_count = set()\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definimos funciones que nos ayudarán a sacar los datos de las cajas de detección, en este caso las coordenadas de la caja y el _tracking ID_ de la clase detectada."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:15:19.226243Z",
     "start_time": "2024-11-08T16:15:19.210201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_box_coordinates(box, parent=None):\n",
    "    if parent is not None:\n",
    "        dx, dy, _, _ = get_box_coordinates(parent)\n",
    "    else:\n",
    "        dx, dy = 0, 0\n",
    "    x1, y1, x2, y2 = box.xyxy[0]\n",
    "    x1, y1, x2, y2 = int(x1) + dx, int(y1) + dy, int(x2) + dx, int(y2) + dy\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "\n",
    "def get_box_id(box):\n",
    "    return None if box.id is None else int(box.id[0].tolist())"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creamos la clase `Detection`. Esta clase nos facilitará acceder a datos comunes de las cajas de detección y a guardar los datos en el archivo CSV"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:15:22.440574Z",
     "start_time": "2024-11-08T16:15:22.435575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Detection:\n",
    "    def __init__(self, box):\n",
    "        self.x1, self.y1, self.x2, self.y2 = get_box_coordinates(box)\n",
    "        self.box_class = int(box.cls[0])\n",
    "        self.class_name = yolo_classes[self.box_class]\n",
    "        self.track_id = get_box_id(box)\n",
    "        self.confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "        self.has_license_plate = False\n",
    "        self.m_confidence = None\n",
    "        self.my2 = None\n",
    "        self.mx2 = None\n",
    "        self.mx1 = None\n",
    "        self.my1 = None\n",
    "\n",
    "    def add_license_plate(self, boxes):\n",
    "        if len(boxes) < 1: return\n",
    "        box = boxes[0]\n",
    "        self.has_license_plate = True\n",
    "        self.m_confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "        self.mx1, self.my1, self.mx2, self.my2 = get_box_coordinates(box)\n",
    "        self.mx1 += self.x1\n",
    "        self.mx2 += self.x1\n",
    "        self.my2 += self.y1\n",
    "        self.my2 += self.y1\n",
    "\n",
    "    def write_into_csv(self, csv_writer, frame_count):\n",
    "        csv_writer.writerow(\n",
    "            [frame_count, self.class_name, self.confidence, self.track_id, self.x1, self.y1, self.x2, self.y2,\n",
    "             self.has_license_plate, self.m_confidence, self.mx1, self.my1, self.mx2, self.my2]\n",
    "        )\n",
    "\n",
    "    def is_person(self):\n",
    "        return self.box_class == 0\n",
    "\n",
    "    def get_cropped_frame(self, frame):\n",
    "        return frame[self.y1:self.y2, self.x1:self.x2]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creamos otra función que nos facilitará dibujar los rectángulos, sobre todo si corresponden a los de dentro de un rectángulo (como es el caso de las matrículas dentro de las cajas del coche), ya que calcula las coordenadas teniendo en cuenta las coordenadas del padre."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:15:26.145562Z",
     "start_time": "2024-11-08T16:15:26.142563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def draw_rectangles(frame, box, text, parent=None, box_color=(0, 255, 0), text_color=(255, 0, 155)):\n",
    "    x1, y1, x2, y2 = get_box_coordinates(box, parent)\n",
    "\n",
    "    box_id = get_box_id(box)\n",
    "    if box_id is not None:\n",
    "        text = f\"{text} - {str(box_id)}\"\n",
    "\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "    cv2.putText(frame, text, [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creamos otras dos funciones que nos permitirán llevar la cuenta de las clases y mostrarlas en el video."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:15:29.146954Z",
     "start_time": "2024-11-08T16:15:29.137955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_class_count(detection, frame):\n",
    "    if detection.track_id not in track_count:\n",
    "        track_count.add(detection.track_id)\n",
    "        class_counts[detection.class_name] += 1\n",
    "\n",
    "    text = generate_count_text()\n",
    "\n",
    "    x = 0\n",
    "    y = 50\n",
    "    font_scale = 0.8\n",
    "    thickness = 2\n",
    "\n",
    "    text_w, text_h = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]\n",
    "\n",
    "    cv2.rectangle(frame, (text_w, text_h + 10), (x, y), (180, 180, 180), cv2.FILLED)\n",
    "    cv2.putText(frame, generate_count_text(), (x, y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), thickness)\n",
    "\n",
    "\n",
    "def generate_count_text():\n",
    "    found_classes = []\n",
    "    for k, v in class_counts.items():\n",
    "        if v == 1:\n",
    "            found_classes.append(f\"{v} {k}\")\n",
    "        elif v > 1:\n",
    "            found_classes.append(f\"{v} {k}S\")\n",
    "\n",
    "    return \" - \".join(found_classes)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creamos la función que realizará las detecciones, dibujará los rectángulos de la mismas y actualizará el conteo de clases. Además, para las detecciones que no son personas, se buscará y dibujará el rectángulo de la matrícula."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:15:31.951198Z",
     "start_time": "2024-11-08T16:15:31.937200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def track_objects(result, frame):\n",
    "    detections = []\n",
    "    for box in result.boxes:\n",
    "        detection = Detection(box)\n",
    "        update_class_count(detection, frame)\n",
    "        if detection.is_person():\n",
    "            draw_rectangles(frame, box, detection.class_name)\n",
    "        else:\n",
    "            draw_rectangles(frame, box, detection.class_name)\n",
    "            result_license_plates = model_plates(detection.get_cropped_frame(frame), verbose=False)\n",
    "            detection.add_license_plate(result_license_plates[0].boxes)\n",
    "            for box2 in result_license_plates[0].boxes:\n",
    "                draw_rectangles(frame, box2, \"MATRICULA\", parent=box, box_color=(255, 0, 0),\n",
    "                                text_color=(0, 0, 255))\n",
    "        detections.append(detection)\n",
    "    return detections"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Por último, creamos la función principal que abrirá el video e irá guardando tanto el video procesado con los resultados como el csv con los datos recolectados."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:15:35.645412Z",
     "start_time": "2024-11-08T16:15:35.629413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_video(video, export_video, export_csv, show=False):\n",
    "    vid = cv2.VideoCapture(video)\n",
    "\n",
    "    total_frames = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    frame_count = 0\n",
    "\n",
    "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    output_video = cv2.VideoWriter(\n",
    "        export_video,\n",
    "        cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "        fps,\n",
    "        (frame_width, frame_height)\n",
    "    )\n",
    "    csv_file = open(export_csv, mode='w', newline='')\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"fotograma\", \"tipo_objeto\", \"confianza\", \"identificador_tracking\", \"x1\", \"y1\", \"x2\", \"y2\",\n",
    "                         \"tiene_matricula\", \"m_confianza\", \"mx1\", \"my1\", \"mx2\", \"my2\"])\n",
    "\n",
    "    while vid.isOpened():\n",
    "        ret, frame = vid.read()\n",
    "        frame_count += 1\n",
    "        if ret:\n",
    "            percentage = math.floor(frame_count / total_frames * 100)\n",
    "            print(\"\\r\", f\"{percentage}% procesado...\", end=\"\")\n",
    "            result = model.track(frame, persist=True, classes=list(yolo_classes.keys()), verbose=False)\n",
    "            detections = track_objects(result[0], frame)\n",
    "            for detection in detections:\n",
    "                detection.write_into_csv(csv_writer, frame_count)\n",
    "            output_video.write(frame)\n",
    "            if show: cv2.imshow('frame', frame)\n",
    "        else:\n",
    "            break\n",
    "        if cv2.waitKey(20) == 27:\n",
    "            break\n",
    "\n",
    "    print(\"\\r100% procesado!\")\n",
    "    print(f\"\\nVideo guardado en el archivo {export_video}\")\n",
    "    print(f\"Archivo csv guardado en el archivo {export_csv}\")\n",
    "    output_video.release()\n",
    "    csv_file.close()\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ejecutamos la función con el vídeo de ejemplo. El vídeo procesado se guardará en el archivo `video_final.mp4`, y el csv en `datos.csv`. Para mostrar el procesamiento en tiempo real se puede poner el parámetro `show` a `True`\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:22:21.636560Z",
     "start_time": "2024-11-08T16:15:40.991349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#tanto el video de prueba como el final no se pueden subir a GitHub por su gran tamaño. El link al video final se puede encontrar en el readme.\n",
    "\n",
    "process_video(\"video_prueba.mp4\", \"video_final.mp4\", \"datos.csv\", show=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% procesado!...\n",
      "\n",
      "Video guardado en el archivo video_final.mp4\n",
      "Archivo csv guardado en el archivo datos.csv\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
